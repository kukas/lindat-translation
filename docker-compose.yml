version: '2.4'
services:
  # Tensorflow serving
  serving:
    image: "tensorflow/serving@sha256:6651f4839e1124dbde75ee531825112af0a6b8ef082c88ab14ca53eb69a2e4bb"
    #command: --enable_batching=true --model_config_file=/configs/model.config --batching_parameters_file=/config/batching.config
    #ports:
    # - 9000:8500
    environment:
      - MODEL_NAME=en-hi
    volumes:
      - type: bind
        source: ./models/t2t-model.en-hi/export/Servo
        target: /models/en-hi
    tty: true
    stdin_open: true
    platform: linux
  # frontend
  frontend:
    build: .
    ports:
      - 5000:5000
    environment:
      - LOCAL_SETTINGS=../.docker_config.py
    depends_on:
      - serving
    tty: true
    stdin_open: true
    platform: linux
